{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12289446,"sourceType":"datasetVersion","datasetId":3442424},{"sourceId":14420143,"sourceType":"datasetVersion","datasetId":9210060}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ü¶ã Butterfly Species Classification - Multi-Model Training\n## Version 3.0 - Production Ready for Kaggle 2026\n\n**Train & Compare 4 State-of-the-Art Models:**\n1. üèõÔ∏è **VGG16** - Classic deep architecture (138M params)\n2. üîó **ResNet50** - Residual connections (25M params)\n3. ‚ö° **EfficientNetB0** - Compound scaling (5.3M params) - Usually wins!\n4. üì± **MobileNetV2** - Lightweight (3.5M params)\n\n**Automatic Model Selection:** The notebook will train all 4 models and automatically select the best one!\n\n**Expected Time:** ~100-120 minutes on Kaggle T4 GPU\n\n**Expected Accuracy:** 85-88% (best model)\n\n---","metadata":{}},{"cell_type":"markdown","source":"## üì¶ Step 1: Import Libraries\n\n**No installations needed!** Kaggle has everything pre-installed.\n\nThose CUDA warnings are normal - just ignore them!","metadata":{}},{"cell_type":"code","source":"# Import all required libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB0, MobileNetV2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\n\nimport os\nimport json\nimport time\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seeds for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# Display environment info\nprint(\"=\" * 70)\nprint(\"ENVIRONMENT CHECK\")\nprint(\"=\" * 70)\nprint(f\"TensorFlow: {tf.__version__}\")\nprint(f\"Keras: {keras.__version__}\")\nprint(f\"NumPy: {np.__version__}\")\nprint(f\"Pandas: {pd.__version__}\")\nprint(f\"sklearn: {sklearn.__version__}\")\nfrom platform import python_version\n# print(python_version())\nprint(f\"Python: {python_version()}\")\n\nprint(f\"\\nGPU Devices: {tf.config.list_physical_devices('GPU')}\")\nprint(\"=\"*70)\nprint(\"=\" * 70)\nprint(\"\\n‚úÖ All libraries loaded successfully!\")\nprint(\"‚úÖ Ready to train 4 models!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T14:07:45.734692Z","iopub.execute_input":"2026-01-07T14:07:45.734949Z","iopub.status.idle":"2026-01-07T14:08:02.246066Z","shell.execute_reply.started":"2026-01-07T14:07:45.734931Z","shell.execute_reply":"2026-01-07T14:08:02.245257Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üìÇ Step 2: Load Dataset\n\nMake sure you've added the butterfly dataset to your notebook!","metadata":{}},{"cell_type":"code","source":"# Configure paths (Kaggle format)\nDATASET_PATH = '/kaggle/input/butterfly-image-classification'\nCSV_FILE = os.path.join(DATASET_PATH, 'Training_set.csv')\nIMAGES_DIR = os.path.join(DATASET_PATH, 'train')\n\n# Verify dataset exists\nprint(\"Checking dataset...\")\nprint(f\"CSV exists: {os.path.exists(CSV_FILE)}\")\nprint(f\"Images dir exists: {os.path.exists(IMAGES_DIR)}\")\n\nif not os.path.exists(CSV_FILE):\n    raise FileNotFoundError(\n        \"Dataset not found! Please add 'butterfly-image-classification' dataset in Kaggle.\"\n    )\n\n# Load dataset\nprint(\"\\nLoading dataset...\")\ndf = pd.read_csv(CSV_FILE)\ndf['filepath'] = df['filename'].apply(lambda x: os.path.join(IMAGES_DIR, x))\n\n# Verify all files exist\nexisting_files = df['filepath'].apply(os.path.exists)\nprint(f\"Files found: {existing_files.sum()}/{len(df)} ({existing_files.sum()/len(df)*100:.1f}%)\")\n\nif not all(existing_files):\n    print(f\"‚ö†Ô∏è Warning: {(~existing_files).sum()} files missing. Removing from dataset.\")\n    df = df[existing_files].reset_index(drop=True)\n\n# Dataset statistics\nprint(f\"\\n{'='*70}\")\nprint(\"DATASET STATISTICS\")\nprint(f\"{'='*70}\")\nprint(f\"Total images: {len(df)}\")\nprint(f\"Number of species: {df['label'].nunique()}\")\nprint(f\"Images per species (avg): {len(df) / df['label'].nunique():.1f}\")\n\n# Class distribution\nclass_counts = df['label'].value_counts()\nprint(f\"\\nClass balance:\")\nprint(f\"  Min: {class_counts.min()} images\")\nprint(f\"  Max: {class_counts.max()} images\")\nprint(f\"  Mean: {class_counts.mean():.1f} images\")\nprint(f\"{'='*70}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T14:08:19.519777Z","iopub.execute_input":"2026-01-07T14:08:19.520754Z","iopub.status.idle":"2026-01-07T14:08:30.491503Z","shell.execute_reply.started":"2026-01-07T14:08:19.520726Z","shell.execute_reply":"2026-01-07T14:08:30.490796Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ‚úÇÔ∏è Step 3: Train/Validation Split\n\nUsing 80/20 split with stratification to maintain class balance.","metadata":{}},{"cell_type":"code","source":"# Create stratified split\nprint(\"Creating train/validation split...\")\ntrain_df, val_df = train_test_split(\n    df,\n    test_size=0.2,\n    stratify=df['label'],\n    random_state=42  # Fixed seed for reproducibility\n)\n\nprint(f\"\\n‚úÖ Split created:\")\nprint(f\"Training set: {len(train_df)} images ({len(train_df)/len(df)*100:.1f}%)\")\nprint(f\"Validation set: {len(val_df)} images ({len(val_df)/len(df)*100:.1f}%)\")\n\n# Create class indices mapping\nunique_labels = sorted(df['label'].unique())\nclass_indices = {label: idx for idx, label in enumerate(unique_labels)}\nnum_classes = len(class_indices)\n\nprint(f\"\\nNumber of classes: {num_classes}\")\nprint(f\"Classes will be saved to 'class_indices.json'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T14:08:35.775085Z","iopub.execute_input":"2026-01-07T14:08:35.775740Z","iopub.status.idle":"2026-01-07T14:08:35.794152Z","shell.execute_reply.started":"2026-01-07T14:08:35.775717Z","shell.execute_reply":"2026-01-07T14:08:35.793565Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üñºÔ∏è Step 4: Create Data Generators\n\nTraining data will be augmented to improve generalization.","metadata":{}},{"cell_type":"code","source":"# Configuration\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32\n\nprint(f\"Image size: {IMG_SIZE}\")\nprint(f\"Batch size: {BATCH_SIZE}\")\n\n# Training data generator with augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    zoom_range=0.2,\n    shear_range=0.15,\n    fill_mode='nearest'\n)\n\n# Validation data generator (no augmentation)\nval_datagen = ImageDataGenerator(rescale=1./255)\n\n# Create generators\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    x_col='filepath',\n    y_col='label',\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True,\n    seed=42\n)\n\nval_generator = val_datagen.flow_from_dataframe(\n    val_df,\n    x_col='filepath',\n    y_col='label',\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False\n)\n\nprint(f\"\\n‚úÖ Data generators created:\")\nprint(f\"Training batches: {len(train_generator)}\")\nprint(f\"Validation batches: {len(val_generator)}\")\nprint(f\"Steps per epoch: {len(train_generator)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T14:08:38.966225Z","iopub.execute_input":"2026-01-07T14:08:38.966797Z","iopub.status.idle":"2026-01-07T14:08:42.274011Z","shell.execute_reply.started":"2026-01-07T14:08:38.966770Z","shell.execute_reply":"2026-01-07T14:08:42.273299Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üèóÔ∏è Step 5: Define Model Builders\n\nFunctions to build each of the 4 architectures.","metadata":{}},{"cell_type":"code","source":"def build_vgg16(num_classes):\n    \"\"\"VGG16: Classic deep architecture, reliable baseline\"\"\"\n    base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    base.trainable = False\n    \n    model = models.Sequential([\n        base,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.BatchNormalization(),\n        layers.Dense(256, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(num_classes, activation='softmax')\n    ], name='VGG16')\n    \n    return model, base\n\ndef build_resnet50(num_classes):\n    \"\"\"ResNet50: Residual connections, good accuracy\"\"\"\n    base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    base.trainable = False\n    \n    model = models.Sequential([\n        base,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.BatchNormalization(),\n        layers.Dense(256, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(num_classes, activation='softmax')\n    ], name='ResNet50')\n    \n    return model, base\n\ndef build_efficientnet(num_classes):\n    \"\"\"EfficientNetB0: State-of-the-art efficiency, often wins!\"\"\"\n    base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    base.trainable = False\n    \n    model = models.Sequential([\n        base,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.BatchNormalization(),\n        layers.Dense(256, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(num_classes, activation='softmax')\n    ], name='EfficientNetB0')\n    \n    return model, base\n\ndef build_mobilenet(num_classes):\n    \"\"\"MobileNetV2: Lightweight and fast, good for deployment\"\"\"\n    base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    base.trainable = False\n    \n    model = models.Sequential([\n        base,\n        layers.GlobalAveragePooling2D(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation='relu'),\n        layers.Dropout(0.5),\n        layers.BatchNormalization(),\n        layers.Dense(256, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(num_classes, activation='softmax')\n    ], name='MobileNetV2')\n    \n    return model, base\n\nprint(\"‚úÖ Model builders defined:\")\nprint(\"  1. VGG16 - Classic deep CNN\")\nprint(\"  2. ResNet50 - Residual learning\")\nprint(\"  3. EfficientNetB0 - Compound scaling\")\nprint(\"  4. MobileNetV2 - Lightweight\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T14:08:51.945971Z","iopub.execute_input":"2026-01-07T14:08:51.946532Z","iopub.status.idle":"2026-01-07T14:08:51.956740Z","shell.execute_reply.started":"2026-01-07T14:08:51.946507Z","shell.execute_reply":"2026-01-07T14:08:51.955912Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üéØ Step 6: Define Training Function\n\nTwo-phase training: Transfer learning + Fine-tuning","metadata":{}},{"cell_type":"code","source":"def train_model(model, base_model, model_name, train_gen, val_gen):\n    \"\"\"\n    Train a model with two phases:\n    Phase 1: Transfer learning (base frozen)\n    Phase 2: Fine-tuning (last layers unfrozen)\n    \"\"\"\n    print(f\"\\n{'='*70}\")\n    print(f\"TRAINING: {model_name}\")\n    print(f\"{'='*70}\")\n    print(f\"Total parameters: {model.count_params():,}\")\n    \n    start_time = time.time()\n    \n    # Phase 1: Transfer Learning\n    print(f\"\\n--- Phase 1: Transfer Learning (base frozen) ---\")\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    callbacks = [\n        EarlyStopping(\n            monitor='val_loss',\n            patience=8,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.5,\n            patience=3,\n            min_lr=1e-7,\n            verbose=1\n        )\n    ]\n    \n    history1 = model.fit(\n        train_gen,\n        validation_data=val_gen,\n        epochs=20,\n        callbacks=callbacks,\n        verbose=1\n    )\n    \n    # Phase 2: Fine-tuning\n    print(f\"\\n--- Phase 2: Fine-tuning (last 4 layers unfrozen) ---\")\n    base_model.trainable = True\n    for layer in base_model.layers[:-4]:\n        layer.trainable = False\n    \n    trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n    print(f\"Trainable parameters: {trainable_params:,}\")\n    \n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    history2 = model.fit(\n        train_gen,\n        validation_data=val_gen,\n        epochs=10,\n        callbacks=callbacks,\n        initial_epoch=len(history1.history['loss']),\n        verbose=1\n    )\n    \n    train_time = time.time() - start_time\n    \n    # Final Evaluation\n    print(f\"\\n--- Final Evaluation ---\")\n    val_gen.reset()\n    val_loss, val_acc = model.evaluate(val_gen, verbose=0)\n    \n    # Calculate F1-score\n    val_gen.reset()\n    predictions = model.predict(val_gen, verbose=0)\n    y_pred = np.argmax(predictions, axis=1)\n    y_true = val_gen.classes\n    f1 = f1_score(y_true, y_pred, average='weighted')\n    \n    # Combine histories (handle case where Phase 2 stops immediately)\n    history = {\n        'loss': history1.history['loss'] + (history2.history.get('loss', [])),\n        'val_loss': history1.history['val_loss'] + (history2.history.get('val_loss', [])),\n        'accuracy': history1.history['accuracy'] + (history2.history.get('accuracy', [])),\n        'val_accuracy': history1.history['val_accuracy'] + (history2.history.get('val_accuracy', []))\n    }\n    \n    results = {\n        'model_name': model_name,\n        'val_accuracy': float(val_acc),\n        'val_loss': float(val_loss),\n        'f1_score': float(f1),\n        'train_time_minutes': train_time / 60,\n        'total_params': int(model.count_params()),\n        'history': history\n    }\n    \n    print(f\"\\n‚úÖ {model_name} Training Complete!\")\n    print(f\"   Accuracy: {val_acc*100:.2f}%\")\n    print(f\"   F1-Score: {f1:.4f}\")\n    print(f\"   Loss: {val_loss:.4f}\")\n    print(f\"   Time: {train_time/60:.1f} minutes\")\n    print(f\"{'='*70}\\n\")\n    \n    return model, results\n\nprint(\"‚úÖ Training function ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T14:09:13.205911Z","iopub.execute_input":"2026-01-07T14:09:13.206594Z","iopub.status.idle":"2026-01-07T14:09:13.216725Z","shell.execute_reply.started":"2026-01-07T14:09:13.206570Z","shell.execute_reply":"2026-01-07T14:09:13.216008Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üöÄ Step 7: Train All 4 Models\n\n**This will take ~100-120 minutes total!**\n\nPerfect time for:\n- ‚òï Coffee breaks\n- üìö Reading documentation\n- üçï Lunch\n- üö∂ Short walk","metadata":{}},{"cell_type":"code","source":"# Define models to train\nmodels_to_train = [\n    ('VGG16', build_vgg16),\n    ('ResNet50', build_resnet50),\n    ('EfficientNetB0', build_efficientnet),\n    ('MobileNetV2', build_mobilenet)\n]\n\n# Storage for results\nall_results = []\ntrained_models = {}\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"STARTING MULTI-MODEL TRAINING\")\nprint(\"=\"*70)\nprint(f\"Models to train: {len(models_to_train)}\")\nprint(f\"Estimated time: {len(models_to_train) * 25}-{len(models_to_train) * 30} minutes\")\nprint(f\"Start time: {datetime.now().strftime('%H:%M:%S')}\")\nprint(\"=\"*70 + \"\\n\")\n\ntotal_start = time.time()\n\n# Train each model\nfor idx, (name, builder_func) in enumerate(models_to_train, 1):\n    print(f\"\\nüîÑ [{idx}/{len(models_to_train)}] Starting {name}...\")\n    print(f\"Current time: {datetime.now().strftime('%H:%M:%S')}\")\n    \n    # Build model\n    model, base_model = builder_func(num_classes)\n    \n    # Train model\n    trained_model, results = train_model(\n        model, base_model, name,\n        train_generator, val_generator\n    )\n    \n    # Store results\n    all_results.append(results)\n    trained_models[name] = trained_model\n    \n    # Progress update\n    elapsed = (time.time() - total_start) / 60\n    remaining = (len(models_to_train) - idx) * (elapsed / idx)\n    print(f\"\\nüìä Progress: {idx}/{len(models_to_train)} complete\")\n    print(f\"‚è±Ô∏è  Elapsed: {elapsed:.1f} min | Estimated remaining: {remaining:.1f} min\")\n    print(f\"Estimated completion: {(datetime.now() + pd.Timedelta(minutes=remaining)).strftime('%H:%M:%S')}\")\n\ntotal_time = (time.time() - total_start) / 60\nprint(f\"\\n{'='*70}\")\nprint(\"üéâ ALL MODELS TRAINED!\")\nprint(f\"{'='*70}\")\nprint(f\"Total training time: {total_time:.1f} minutes ({total_time/60:.1f} hours)\")\nprint(f\"Completion time: {datetime.now().strftime('%H:%M:%S')}\")\nprint(f\"{'='*70}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T14:09:26.676873Z","iopub.execute_input":"2026-01-07T14:09:26.677157Z","iopub.status.idle":"2026-01-07T15:37:13.204273Z","shell.execute_reply.started":"2026-01-07T14:09:26.677136Z","shell.execute_reply":"2026-01-07T15:37:13.203398Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## \nüìä Step 8: Compare Results & Select Best Model\n\nComparing all 4 models to find the winner!","metadata":{}},{"cell_type":"code","source":"# Create comparison DataFrame\ncomparison_df = pd.DataFrame([{\n    'Model': r['model_name'],\n    'Accuracy (%)': r['val_accuracy'] * 100,\n    'F1-Score': r['f1_score'],\n    'Loss': r['val_loss'],\n    'Parameters (M)': r['total_params'] / 1e6,\n    'Time (min)': r['train_time_minutes']\n} for r in all_results])\n\n# Sort by accuracy (descending)\ncomparison_df = comparison_df.sort_values('Accuracy (%)', ascending=False).reset_index(drop=True)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"MODEL COMPARISON RESULTS\")\nprint(\"=\"*70)\nprint(comparison_df.to_string(index=False))\nprint(\"=\"*70 + \"\\n\")\n\n# Find best model\nbest_idx = comparison_df['Accuracy (%)'].idxmax()\nbest_model_name = comparison_df.loc[best_idx, 'Model']\nbest_accuracy = comparison_df.loc[best_idx, 'Accuracy (%)']\nbest_f1 = comparison_df.loc[best_idx, 'F1-Score']\nbest_params = comparison_df.loc[best_idx, 'Parameters (M)']\nbest_time = comparison_df.loc[best_idx, 'Time (min)']\n\nprint(f\"\\nüèÜ WINNER: {best_model_name}\")\nprint(f\"{'='*70}\")\nprint(f\"Accuracy: {best_accuracy:.2f}%\")\nprint(f\"F1-Score: {best_f1:.4f}\")\nprint(f\"Parameters: {best_params:.1f}M\")\nprint(f\"Training Time: {best_time:.1f} minutes\")\nprint(f\"{'='*70}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:37:58.940946Z","iopub.execute_input":"2026-01-07T15:37:58.941210Z","iopub.status.idle":"2026-01-07T15:37:58.953007Z","shell.execute_reply.started":"2026-01-07T15:37:58.941192Z","shell.execute_reply":"2026-01-07T15:37:58.952234Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üìà Step 9: Visualize Comparison\n\nCreate beautiful comparison charts!","metadata":{}},{"cell_type":"code","source":"# Set style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\n\n# Create comparison charts\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\nfig.suptitle('ü¶ã Butterfly Classifier - Model Comparison', fontsize=20, fontweight='bold', y=0.995)\n\n# Colors: winner = green, others = blue\ncolors = ['#10b981' if x == best_model_name else '#3b82f6' for x in comparison_df['Model']]\n\n# 1. Accuracy comparison\nax1 = axes[0, 0]\nbars1 = ax1.bar(comparison_df['Model'], comparison_df['Accuracy (%)'], color=colors)\nax1.set_title('Validation Accuracy', fontsize=14, fontweight='bold')\nax1.set_ylabel('Accuracy (%)')\nax1.set_ylim([comparison_df['Accuracy (%)'].min() - 2, 100])\nfor bar in bars1:\n    height = bar.get_height()\n    ax1.text(bar.get_x() + bar.get_width()/2., height,\n             f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\nax1.grid(axis='y', alpha=0.3)\nax1.tick_params(axis='x', rotation=45)\n\n# 2. F1-Score comparison\nax2 = axes[0, 1]\nbars2 = ax2.bar(comparison_df['Model'], comparison_df['F1-Score'], color=colors)\nax2.set_title('F1-Score', fontsize=14, fontweight='bold')\nax2.set_ylabel('F1-Score')\nax2.set_ylim([comparison_df['F1-Score'].min() - 0.02, 1.0])\nfor bar in bars2:\n    height = bar.get_height()\n    ax2.text(bar.get_x() + bar.get_width()/2., height,\n             f'{height:.3f}', ha='center', va='bottom', fontweight='bold')\nax2.grid(axis='y', alpha=0.3)\nax2.tick_params(axis='x', rotation=45)\n\n# 3. Parameters vs Accuracy scatter\nax3 = axes[1, 0]\nscatter = ax3.scatter(comparison_df['Parameters (M)'], comparison_df['Accuracy (%)'],\n                      s=300, alpha=0.6, c=colors, edgecolors='black', linewidth=2)\nfor idx, row in comparison_df.iterrows():\n    ax3.annotate(row['Model'], (row['Parameters (M)'], row['Accuracy (%)']),\n                 xytext=(5, 5), textcoords='offset points', fontweight='bold')\nax3.set_title('Model Size vs Accuracy', fontsize=14, fontweight='bold')\nax3.set_xlabel('Parameters (Millions)')\nax3.set_ylabel('Accuracy (%)')\nax3.grid(alpha=0.3)\n\n# 4. Training time comparison\nax4 = axes[1, 1]\nbars4 = ax4.bar(comparison_df['Model'], comparison_df['Time (min)'], color=colors)\nax4.set_title('Training Time', fontsize=14, fontweight='bold')\nax4.set_ylabel('Time (minutes)')\nfor bar in bars4:\n    height = bar.get_height()\n    ax4.text(bar.get_x() + bar.get_width()/2., height,\n             f'{height:.1f}', ha='center', va='bottom', fontweight='bold')\nax4.grid(axis='y', alpha=0.3)\nax4.tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\nplt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"‚úÖ Comparison chart saved as 'model_comparison.png'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:38:11.405720Z","iopub.execute_input":"2026-01-07T15:38:11.406238Z","iopub.status.idle":"2026-01-07T15:38:12.729252Z","shell.execute_reply.started":"2026-01-07T15:38:11.406214Z","shell.execute_reply":"2026-01-07T15:38:12.728531Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üíæ Step 10: Save Best Model & All Results\n\nSaving everything you need for deployment!","metadata":{}},{"cell_type":"code","source":"print(\"Saving files...\\n\")\n\n# 1. Save best model in MULTIPLE formats for maximum compatibility\nbest_model = trained_models[best_model_name]\n\nprint(\"üíæ Saving model in multiple formats...\")\nprint(\"=\"*70)\n\n# Format 1: .keras (Keras 3.x native - RECOMMENDED for Streamlit)\ntry:\n    best_model.save('butterfly_model_best.keras')\n    print(\"‚úÖ Saved: butterfly_model_best.keras (Keras 3.x native format)\")\n    model_saved = 'keras'\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  .keras format failed: {str(e)[:100]}\")\n    model_saved = 'h5'\n\n# Format 2: Weights only (.weights.h5 - Most compatible fallback)\ntry:\n    best_model.save_weights('butterfly_model_best.weights.h5')\n    print(\"‚úÖ Saved: butterfly_model_best.weights.h5 (weights only)\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  Weights save failed: {str(e)[:100]}\")\n\n# Format 3: H5 format (Legacy - for backward compatibility)\ntry:\n    # Remove the deprecated save_format argument\n    best_model.save('butterfly_model_best.h5')\n    print(\"‚úÖ Saved: butterfly_model_best.h5 (H5 format)\")\n    if model_saved != 'keras':\n        model_saved = 'h5'\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  H5 format failed: {str(e)[:100]}\")\n\n# Format 4: SavedModel format (TensorFlow native - for production)\ntry:\n    best_model.export('butterfly_model_savedmodel')\n    print(\"‚úÖ Saved: butterfly_model_savedmodel/ (TensorFlow SavedModel)\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  SavedModel export failed: {str(e)[:100]}\")\n\nprint(\"=\"*70)\nprint(f\"\\nüì¶ Model saved in multiple formats!\")\nprint(f\"   Primary format: {model_saved}\")\nprint(f\"   ‚≠ê RECOMMENDED: Use 'butterfly_model_best.keras' for Streamlit!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:38:22.648743Z","iopub.execute_input":"2026-01-07T15:38:22.649776Z","iopub.status.idle":"2026-01-07T15:38:29.500935Z","shell.execute_reply.started":"2026-01-07T15:38:22.649748Z","shell.execute_reply":"2026-01-07T15:38:29.500173Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üìä Step 11: Display Final Summary\n\nComplete overview of your training results!","metadata":{}},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*70)\nprint(\"üéâ TRAINING COMPLETE - FINAL SUMMARY\")\nprint(\"=\"*70)\n\nprint(f\"\\nüìÖ Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(f\"‚è±Ô∏è  Total Time: {total_time:.1f} minutes ({total_time/60:.2f} hours)\")\nprint(f\"üñ•Ô∏è  Environment: TensorFlow {tf.__version__}, Keras {keras.__version__}\")\nprint(f\"üéÆ GPUs Used: {len(tf.config.list_physical_devices('GPU'))}\")\n\nprint(f\"\\nüìä Dataset:\")\nprint(f\"   Total Images: {len(df)}\")\nprint(f\"   Training: {len(train_df)} images\")\nprint(f\"   Validation: {len(val_df)} images\")\nprint(f\"   Species: {num_classes}\")\n\nprint(f\"\\nüèÜ Winner: {best_model_name}\")\nprint(f\"   Accuracy: {best_accuracy:.2f}%\")\nprint(f\"   F1-Score: {best_f1:.4f}\")\nprint(f\"   Parameters: {best_params:.1f}M\")\nprint(f\"   Training Time: {best_time:.1f} minutes\")\n\nprint(f\"\\nüìà All Models Ranked:\")\nfor idx, row in comparison_df.iterrows():\n    rank_emoji = \"ü•á\" if idx == 0 else \"ü•à\" if idx == 1 else \"ü•â\" if idx == 2 else \"  \"\n    print(f\"   {rank_emoji} {idx+1}. {row['Model']}: {row['Accuracy (%)']:.2f}% (F1: {row['F1-Score']:.3f})\")\n\nprint(f\"\\nüìÅ Files Saved:\")\nprint(f\"   ‚úÖ butterfly_model_best.{model_saved}\")\nprint(f\"   ‚úÖ class_indices.json\")\nprint(f\"   ‚úÖ model_info.json\")\nprint(f\"   ‚úÖ model_comparison.csv\")\nprint(f\"   ‚úÖ model_comparison.png\")\n\nprint(f\"\\nüöÄ Next Steps:\")\nprint(f\"   1. Download all 5 files from the Output tab\")\nprint(f\"   2. Install locally: pip install tensorflow streamlit plotly\")\nprint(f\"   3. Run: streamlit run streamlit_app.py\")\nprint(f\"   4. Deploy with Docker or to cloud!\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"üéì Perfect for your capstone project!\")\nprint(\"üíº Portfolio-quality machine learning project!\")\nprint(\"=\"*70)\n\nprint(f\"\\n‚ú® Your butterfly classifier is ready! ü¶ã\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:40:48.046384Z","iopub.execute_input":"2026-01-07T15:40:48.046989Z","iopub.status.idle":"2026-01-07T15:40:48.055794Z","shell.execute_reply.started":"2026-01-07T15:40:48.046964Z","shell.execute_reply":"2026-01-07T15:40:48.055034Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n## üéâ Congratulations! Training Complete!\n\n### ‚úÖ What You Have:\n\n1. **butterfly_model_best.h5** (or .keras) - Your winning model\n2. **class_indices.json** - Species name mapping (75 species)\n3. **model_info.json** - Complete training metadata + all results\n4. **model_comparison.csv** - Comparison table (for reports)\n5. **model_comparison.png** - Visual charts (for presentations)\n\n### üìä Expected Results:\n\nTypical performance:\n- ü•á **EfficientNetB0**: ~87-88% accuracy (usually wins!)\n- ü•à **ResNet50**: ~86-87% accuracy\n- ü•â **VGG16**: ~85-86% accuracy  \n- üì± **MobileNetV2**: ~83-85% accuracy (fastest!)\n\n### üöÄ Next Steps:\n\n1. **Download Files**\n   - Go to Output tab\n   - Download all 5 files\n\n2. **Setup Locally**\n   ```bash\n   pip install tensorflow streamlit plotly numpy pandas Pillow\n   ```\n\n3. **Run Streamlit App**\n   ```bash\n   streamlit run streamlit_app.py\n   ```\n\n4. **Deploy**\n   - Docker: `docker compose up -d`\n   - Cloud: AWS, Azure, GCP\n\n### üéì For Your Capstone:\n\nYou can now present:\n- ‚úÖ Systematic comparison of 4 architectures\n- ‚úÖ Data-driven model selection\n- ‚úÖ Professional methodology\n- ‚úÖ Quantitative results (accuracy, F1, training time)\n- ‚úÖ Visual comparison charts\n- ‚úÖ Production-ready deployment\n\n### üìö Documentation:\n\nCheck the `model_info.json` file for:\n- Exact training parameters\n- All model metrics\n- Environment versions\n- Everything you need for your report!\n\n---\n\n**üéä You've successfully trained and compared 4 deep learning models! üéä**\n\n**ü¶ã Your butterfly classifier is production-ready! ü¶ã**","metadata":{}},{"cell_type":"code","source":"# # Re-save model in Keras 3.x native format\n# print(\"Re-saving model in Keras 3.x format...\")\n\n# # Load the problematic model\n# import tensorflow as tf\n# model = tf.keras.models.load_model('/kaggle/input/butterfly-train-model/butterfly_model_best.h5', compile=False)\n\n# # Compile it\n# model.compile(\n#     optimizer='adam',\n#     loss='categorical_crossentropy',\n#     metrics=['accuracy']\n# )\n\n# # Save in new format\n# model.export('butterfly_model_best.keras')\n# print(\"‚úÖ Saved! Download this .keras file instead\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T11:01:48.557384Z","iopub.execute_input":"2026-01-07T11:01:48.557945Z","iopub.status.idle":"2026-01-07T11:01:57.775824Z","shell.execute_reply.started":"2026-01-07T11:01:48.557914Z","shell.execute_reply":"2026-01-07T11:01:57.775110Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r working_directory.zip /kaggle/working/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:41:38.739884Z","iopub.execute_input":"2026-01-07T15:41:38.740193Z","iopub.status.idle":"2026-01-07T15:41:42.135190Z","shell.execute_reply.started":"2026-01-07T15:41:38.740173Z","shell.execute_reply":"2026-01-07T15:41:42.134132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Save class indices\nclass_indices = train_generator.class_indices\nwith open('class_indices.json', 'w') as f:\n    json.dump(class_indices, f, indent=2)\nprint(f\"‚úì Class indices saved\")\n\n# Save model comparison\ncomparison_df.to_csv('model_comparison.csv', index=False)\nprint(f\"‚úì Model comparison saved\")\n\n# Save detailed results\nmodel_info = {\n    'best_model': best_model_name,\n    'accuracy': float(best_accuracy),\n    'f1_score': float(best_f1),\n    'num_classes': NUM_CLASSES,\n    'image_size': IMG_SIZE,\n    'model_architecture': best_model_name,\n    'total_images': len(df),\n    'train_images': len(train_df),\n    'val_images': len(val_df),\n    'all_models': [\n        {\n            'name': r['model_name'],\n            'accuracy': r['accuracy'],\n            'f1_score': r['f1_score'],\n            'parameters': r['total_params'],\n            'training_time': r['training_time']\n        }\n        for r in all_results\n    ]\n}\n\nwith open('model_info.json', 'w') as f:\n    json.dump(model_info, f, indent=2)\nprint(f\"‚úì Model info saved\")\n\nprint(f\"\\n{'='*70}\")\nprint(\"FILES READY FOR DOWNLOAD:\")\nprint(f\"{'='*70}\")\nprint(\"1. butterfly_model_best.h5 (~21 MB) - Best trained model\")\nprint(\"2. class_indices.json - Species name mapping\")\nprint(\"3. model_info.json - Training details & comparison\")\nprint(\"4. model_comparison.csv - Comparison table\")\nprint(\"5. model_comparison.png - Comparison chart\")\nprint(f\"{'='*70}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T16:21:21.574644Z","iopub.execute_input":"2026-01-07T16:21:21.575093Z","iopub.status.idle":"2026-01-07T16:21:21.891201Z","shell.execute_reply.started":"2026-01-07T16:21:21.575063Z","shell.execute_reply":"2026-01-07T16:21:21.890262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}